{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50902961",
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTANT ###\n",
    "#Throughout, we use RHCTAG and hRAG, RCCTAG and cRAG, etc. interchangeably\n",
    "\n",
    "from PosSelect_Functions_Old import *\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import seaborn as sns\n",
    "from scipy.stats import mannwhitneyu as mwu\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import ttest_rel\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from scipy.stats import wilcoxon\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats import fisher_exact\n",
    "from scipy.stats import norm\n",
    "from collections import Counter\n",
    "from scipy.stats import binomtest\n",
    "import os\n",
    "\n",
    "hfont = {'fontname':'Arial'}\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "#Code borrowed heavily from here: https://stackoverflow.com/questions/62375034/find-non-overlapping-area-between-two-kde-plots\n",
    "plt.rcParams.update(\n",
    "    {\"text.usetex\": False}\n",
    ")\n",
    "\n",
    "def parse_table(i):\n",
    "    return [int(x) for x in i.replace(\"[\", \"\").replace(\"]\", \"\").split(\",\")]\n",
    "\n",
    "d_abrev = {\"LiangSteinNeuron\":\"FC exc. neur.\", \"FetalChondrocytes\":\"F chond.\", \"SertoliMale\":\"FG sertoli\", \"preGC_IIaFemale\":\"FG preGC IIa\",\\\n",
    "          \"NeuralFemale\":\"FG neur.\", \"FetalGonadImmuneFemale\":\"FG immune\", \"VIP\":\"AC VIP inh. neur.\", \"LiangSteinProgenitor\":\"FC prog.\",\\\n",
    "          \"AdultHeartVentricularCardiomyocyte\":\"AH cardiomyo.\", \"AdultLoopOfHenle\":\"AK loop of henle\", \"FetalBrainNeurGlioblast_CB_VZ\":\"FCB glioblast\",\\\n",
    "         \"AdultProximalTubule\":\"AK prox. tub.\", \"FetalLeydigMale\":\"FG leydig\", \"SST\":\"AC SST inh neur.\", \"KosoyRoussosControlMicroglia\":\"AC microglia\",\\\n",
    "         \"FetalBrainFloorPlate\":\"FB fl. plate\", \"FetalArterialECs\":\"FH endoth.\", \"ASCT\":\"AC astro.\", \"FetalBrainCOP\":\"FB COP\",\\\n",
    "         \"AMY\":\"AA neur.\", \"PVALB\":\"AC PVALB inh neur.\", \"ITL23\":\"AC L2-3 IT neur.\", \"FetalBrainNeurCB_GNP_IPC_1\":\"FB inter. prog.\", \"FetalBrainNeurDAergic\":\"FB DA neur.\",\\\n",
    "          \"OGC\":\"AC Oligo.\", \"D1Pu\":\"AP D1 inh neur.\", \"FetalBrainNeurSerotonergic\":\"FB 5-HT neur.\", \"FetalBrainNeurDRG_2\":\"FS DRG neur.\",\\\n",
    "          \"FetalHeartPericytes\":\"FH peri.\", \"FetalHeartEndocardium\":\"FH endocard.\", \"FetalHeartCardiacFibroblasts\":\"FH fibro.\", \"FetalBrainNeurPurkinje_6\":\"FCB Purk. inh neur.\",\\\n",
    "          \"AdultHeartSmoothMuscle\":\"AH smooth musc.\", \"FetalBrainRoofPlate\":\"FB ro. plate\"}\n",
    "\n",
    "#Lowest RHCTAG p-value is in a heart-specific VISTA-verified enhancer near FHL2 and NCK2.  \n",
    "#It doesn't have ASE in cardiomytocytes, though it could be important in other cell types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa2af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to iterate through RAG/RAL results and merge as described in the text\n",
    "def get_rha(typ, folder):\n",
    "    if typ.endswith(\"AL\"):\n",
    "        namm = \"NumDown\"\n",
    "    else:\n",
    "        namm = \"NumUp\"\n",
    "    dff = pd.DataFrame()\n",
    "    files = os.listdir(folder + \"/NotAll/\")\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        #Filter out the bad cell types\n",
    "        if typ in file and \"FetalChondrocytes\" not in file and \"FetalHeartCardiacFibroblasts\" not in file and \"FetalHeartPericytes\" not in file and \"AdultHeartSmoothMuscle\" not in file:\n",
    "            print(file)\n",
    "            if \"Chpreffed\" not in file:\n",
    "                x = pd.read_csv(folder + \"/NotAll/\" + file, sep = \"\\t\")\n",
    "                x = x[x[namm] >= 3]\n",
    "            else:\n",
    "                x2 = pd.read_csv(folder + \"/NotAll/\" + file, sep = \"\\t\")\n",
    "                x2 = x2[x2[namm] >= 3]\n",
    "                x = pd.concat([x, x2])\n",
    "                x[\"Chrom\"] = [j.split(\":\")[0] for j in x[\"Position\"]]\n",
    "                x[\"Pos\"] = [int(j.split(\":\")[1]) for j in x[\"Position\"]]\n",
    "\n",
    "\n",
    "                prev_row = 0\n",
    "                ind = 0\n",
    "                out = []\n",
    "                for chrom in np.unique(x[\"Chrom\"]):\n",
    "                    x2 = x[x[\"Chrom\"].isin([chrom])]\n",
    "                    x2 = x2.sort_values(\"Pos\")\n",
    "                    for index, row in x2.iterrows():\n",
    "                        if ind == 0:\n",
    "                            prev_row = row\n",
    "                            ind = 1\n",
    "                        elif len(np.intersect1d(prev_row[\"Positions\"].split(\";\"), row[\"Positions\"].split(\";\"))):\n",
    "                            new_poss = \";\".join(np.unique(prev_row[\"Positions\"].split(\";\") + row[\"Positions\"].split(\";\")))\n",
    "                            row[\"Positions\"] = new_poss\n",
    "                            row[namm] = len(new_poss.split(\";\"))\n",
    "                            prev_row = row\n",
    "                        else:\n",
    "                            out.append(prev_row)\n",
    "                            prev_row = row\n",
    "                out.append(prev_row)\n",
    "                df = pd.DataFrame(out)\n",
    "                df[\"Cell type\"] = np.repeat(file.replace(\"_\" + typ + \"s\" + \"_AddSumLFC.txt\", \"\").replace(\"_\" + typ + \"s\" + \"_Chpreffed_AddSumLFC.txt\", \"\"), df.shape[0])\n",
    "                dff = pd.concat([df, dff])\n",
    "    try:\n",
    "        dff = dff.drop([0], axis = 1)\n",
    "    except:\n",
    "        pass\n",
    "    print(dff.shape)\n",
    "    dff = dff.dropna(subset = [\"Position\"])\n",
    "    print(dff.shape)\n",
    "    dff[\"Chrom\"]= [x.split(\":\")[0] for x in dff[\"Position\"]]\n",
    "    dff[\"Pos\"]= [int(x.split(\":\")[1]) for x in dff[\"Position\"]]\n",
    "\n",
    "    out = []\n",
    "    for chrom in np.unique(dff[\"Chrom\"]):\n",
    "        dfc = dff[dff[\"Chrom\"] == chrom].sort_values(\"Pos\")\n",
    "        prev_row = 0\n",
    "        ind = 0\n",
    "        for index, row in dfc.iterrows():\n",
    "            if ind == 0:\n",
    "                prev_row = row\n",
    "                ind = 1\n",
    "            elif len(np.intersect1d(prev_row[\"Positions\"].split(\";\"), row[\"Positions\"].split(\";\"))):\n",
    "                new_poss = \";\".join(np.unique(prev_row[\"Positions\"].split(\";\") + row[\"Positions\"].split(\";\")))\n",
    "                row[\"Positions\"] = new_poss\n",
    "                row[namm] = len(new_poss.split(\";\"))\n",
    "                if prev_row[\"Cell type\"] not in row[\"Cell type\"].split(\";\"):\n",
    "                    row[\"Cell type\"] = row[\"Cell type\"] + \";\" + prev_row[\"Cell type\"]\n",
    "                prev_row = row\n",
    "            else:\n",
    "                out.append(prev_row)\n",
    "                prev_row = row\n",
    "    dfn = pd.DataFrame(out)\n",
    "    num_cts = []\n",
    "    for index, row in dfn.iterrows():\n",
    "        num_cts.append(len(row[\"Cell type\"].split(\";\")))\n",
    "    dfn[\"NumCTS\"] = num_cts\n",
    "    dfn.to_csv(typ + \"_Data_Filt.txt\", sep = \"\\t\", index = False)\n",
    "    outtt = []\n",
    "    for index, row in dfn.iterrows():\n",
    "        for i in row[\"Positions\"].split(\";\"):\n",
    "            outtt.append(i)\n",
    "    o = pd.DataFrame(outtt)\n",
    "    o.to_csv(typ + \"_Positions_Filt.txt\", sep = \"\\t\", header = False, index = False)\n",
    "\n",
    "    o[\"Chrom\"] = [j.split(\":\")[0] for j in o[0]]\n",
    "    o[\"Pos1\"] = [str(int(j.split(\":\")[1])-1) for j in o[0]]\n",
    "    o[\"Pos2\"] = [str(int(j.split(\":\")[1])) for j in o[0]]\n",
    "    o[[\"Chrom\", \"Pos1\", \"Pos2\"]].to_csv(typ + \"_Positions_Filt.bed\", sep = \"\\t\", header = None, index = None)\n",
    "    return dfn\n",
    "get_rha(\"RHCTAG\", \"RHCTAGs\")\n",
    "get_rha(\"RHCTAL\", \"RHCTAGs\")\n",
    "get_rha(\"RCCTAG\", \"RCCTAGs\")\n",
    "get_rha(\"RCCTAL\", \"RCCTAGs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cd1258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting approximate number of substitutions in each region\n",
    "for typ in [\"RHCTAG\", \"RHCTAL\", \"RCCTAG\", \"RCCTAL\"]:\n",
    "    for i in d_abrev.keys():\n",
    "        try:\n",
    "            chpn = pd.read_csv(typ.replace(\"L\", \"G\") + \"s/\" + i + \"_\" + typ + \"s_Chpreffed_AddSumLFC.txt\", sep = \"\\t\")\n",
    "            humn = pd.read_csv(typ.replace(\"L\", \"G\") + \"s/\" + i + \"_\" + typ + \"s_AddSumLFC.txt\", sep = \"\\t\")\n",
    "            print(np.mean(humn[\"TotalSites\"]), np.mean(chpn[\"TotalSites\"]))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29642f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging p-value information\n",
    "for typ in [\"RHCTAG\", \"RHCTAL\", \"RCCTAG\", \"RCCTAL\"]:\n",
    "\n",
    "    dfn = pd.read_csv(typ + \"_Data_Filt.txt\", sep = \"\\t\")\n",
    "    dfn_p = pd.DataFrame()\n",
    "    for ct in np.unique(dfn[\"Cell type\"]):\n",
    "        dfn_ct = dfn[dfn['Cell type'] == ct]\n",
    "\n",
    "        chp = pd.DataFrame()\n",
    "        hum = pd.DataFrame()\n",
    "        for i in ct.split(\";\"):\n",
    "            chpn = pd.read_csv(typ.replace(\"L\", \"G\") + \"s/\" + i + \"_\" + typ + \"s_Chpreffed_AddSumLFC.txt\", sep = \"\\t\")\n",
    "            humn = pd.read_csv(typ.replace(\"L\", \"G\") + \"s/\" + i + \"_\" + typ + \"s_AddSumLFC.txt\", sep = \"\\t\")\n",
    "            chp = pd.concat([chp, chpn])\n",
    "            hum = pd.concat([hum, humn])\n",
    "        print(ct)\n",
    "        out = []\n",
    "        for index, row in dfn_ct.iterrows():\n",
    "\n",
    "            chp_p = chp[chp[\"Position\"].isin(row[\"Positions\"].split(\";\"))]\n",
    "            hum_p = hum[hum[\"Position\"].isin(row[\"Positions\"].split(\";\"))]\n",
    "            out.append(list(row) + [np.min(list(chp_p[\"BinomPvalue\"]) + list(hum_p[\"BinomPvalue\"]))])\n",
    "        dfn_new = pd.DataFrame(out)\n",
    "        dfn_new.columns = list(dfn_ct.columns) + [\"BinomPvalue\"]\n",
    "        dfn_p = pd.concat([dfn_p, dfn_new])\n",
    "    dfn_p.to_csv(typ + \"_Data_Filt_WithP.txt\", sep = \"\\t\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea049e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = pd.read_csv(\"RHCTAG_Data_Filt.txt\", sep = \"\\t\")\n",
    "dfnn = dfn[dfn[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"LiangSteinNeuron;ITL23\", \"ITL23;LiangSteinNeuron\"])]\n",
    "\n",
    "k = []\n",
    "\n",
    "for index, row in dfnn.iterrows():\n",
    "    k = k + row[\"Position\"].split(\";\")\n",
    "len(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For human G in GREAT, we observe enrichment for an ion channel category\n",
    "#For chimp G in GREAT, nothing has FDR > 1\n",
    "#For human and chimp L in GREAT, nothing is significant\n",
    "h = pd.read_csv(\"RHCTAG_Data_Filt.txt\", sep = \"\\t\")\n",
    "c = pd.read_csv(\"RCCTAG_Data_Filt.txt\", sep = \"\\t\")\n",
    "h = h[h[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])]\n",
    "c = c[c[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])]\n",
    "h = h[[\"Chrom\", \"Pos\"]]\n",
    "h[\"Pos2\"] = h[\"Pos\"]\n",
    "h[\"Pos\"] = h[\"Pos\"] - 1\n",
    "c = c[[\"Chrom\", \"Pos\"]]\n",
    "c[\"Pos2\"] = c[\"Pos\"]\n",
    "c[\"Pos\"] = c[\"Pos\"] - 1\n",
    "hc = pd.concat([h, c])\n",
    "hc.to_csv(\"RHCTAG_RCCTAG_BackgroundGREAT_Filt_Neur.bed\", sep = \"\\t\", header = False, index = False)\n",
    "h.to_csv(\"RHCTAG_GREAT_Filt_Neur.bed\", sep = \"\\t\", header = False, index = False)\n",
    "c.to_csv(\"RCCTAG_GREAT_Filt_Neur.bed\", sep = \"\\t\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05274e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for typ in [\"RCCTAG\", \"RHCTAG\", \"RCCTAL\", \"RHCTAL\"]:\n",
    "\n",
    "    dfn2 = pd.read_csv(typ + \"_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "\n",
    "    dfn2[\"Chrom\"] = [j.split(\":\")[0] for j in dfn2[\"Position\"]]\n",
    "    dfn2[\"Pos1\"] = [str(int(j.split(\":\")[1])-1) for j in dfn2[\"Position\"]]\n",
    "    dfn2[\"Pos2\"] = [str(int(j.split(\":\")[1])) for j in dfn2[\"Position\"]]\n",
    "    dfn2[[\"Chrom\", \"Pos1\", \"Pos2\"]].to_csv(typ + \"_Index_Positions_Filt.bed\", sep = \"\\t\", header = None, index = None)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad4e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strongest agreement with RHCTAG, but generally see agreement as when we remove it then it is still significant\n",
    "group1 = [\"KosoyRoussosControlMicroglia\", \"AdultHeartVentricularCardiomyocyte\", \"AdultProximalTubule\", \"FetalArterialECs\", \"FetalChondrocytes\", \"SertoliMale\", \"ASCT\"]\n",
    "\n",
    "agr = 0\n",
    "disagr = 0\n",
    "for typ in [\"RCCTAG\", \"RHCTAG\", \"RCCTAL\", \"RHCTAL\"]:\n",
    "    v = pd.read_csv(\"Reinforcing_Intersect/\" + typ + \"_Positions_Filt_JS_Cis_piN.bed\", sep = \"\\t\", header = None)\n",
    "    \n",
    "    dfn2 = pd.read_csv(typ + \"_Data_Filt_WithP.txt\", sep = \"\\t\")\n",
    "    dfn2 = dfn2[dfn2[\"BinomPvalue\"] < 1e-4]\n",
    "    print(dfn2.shape)\n",
    "    neur = []\n",
    "    nneur = []\n",
    "    for index, row in dfn2.iterrows():\n",
    "        if \"LiangSteinNeuron\" in row[\"Cell type\"].split(\";\"):\n",
    "            neur = neur + row[\"Positions\"].split(\";\")\n",
    "        else:\n",
    "            nneur = nneur + row[\"Positions\"].split(\";\")\n",
    "    \n",
    "    vf = v[v[4] != -1]\n",
    "    vf[\"Position\"] = vf[0] + ':' + vf[2].astype(str)\n",
    "    vf = vf[vf[\"Position\"].isin(neur)]\n",
    "    up_rhag = len(np.unique(vf[vf[26].astype(float) > 0][6]))\n",
    "    down_rhag = len(np.unique(vf[vf[26].astype(float) < 0][6]))\n",
    "\n",
    "    b = pd.read_csv(\"Cis_piN_Peaks_JanetSong.txt\", sep = \"\\t\", header = None)\n",
    "    up_back = len(np.unique(b[b[23] > 0][3])) - up_rhag\n",
    "    down_back = len(np.unique(b[b[23] < 0][3])) - down_rhag\n",
    "    \n",
    "    if typ == \"RHCTAG\" or typ == \"RCCTAL\":\n",
    "        agree = up_rhag\n",
    "        disagree = down_rhag\n",
    "    else:\n",
    "        agree = down_rhag\n",
    "        disagree = up_rhag\n",
    "    agr += agree\n",
    "    disagr += disagree\n",
    "    print(typ)\n",
    "    print(fisher_exact([[up_rhag, down_rhag], [up_back - up_rhag, down_back - down_rhag]]))\n",
    "    print([[up_rhag, down_rhag], [up_back - up_rhag, down_back - down_rhag]])\n",
    "print(binomtest(agr, agr + disagr, p = 0.5473251028806584))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b917f4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeating the above, but for non-neuronal elements\n",
    "group1 = [\"KosoyRoussosControlMicroglia\", \"AdultHeartVentricularCardiomyocyte\", \"AdultProximalTubule\", \"FetalArterialECs\", \"FetalChondrocytes\", \"SertoliMale\", \"ASCT\"]\n",
    "\n",
    "agr = 0\n",
    "disagr = 0\n",
    "for typ in [\"RCCTAG\", \"RHCTAG\", \"RCCTAL\", \"RHCTAL\"]:\n",
    "    v = pd.read_csv(\"Reinforcing_Intersect/\" + typ + \"_Positions_Filt_JS_Cis_piN.bed\", sep = \"\\t\", header = None)\n",
    "    \n",
    "    dfn2 = pd.read_csv(typ + \"_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "    neur = []\n",
    "    nneur = []\n",
    "    for index, row in dfn2.iterrows():\n",
    "        if \"LiangSteinNeuron\" in row[\"Cell type\"].split(\";\"):\n",
    "            neur = neur + row[\"Positions\"].split(\";\")\n",
    "        else:\n",
    "            nneur = nneur + row[\"Positions\"].split(\";\")\n",
    "    \n",
    "    vf = v[v[4] != -1]\n",
    "    vf[\"Position\"] = vf[0] + ':' + vf[2].astype(str)\n",
    "    vf = vf[vf[\"Position\"].isin(nneur)]\n",
    "    up_rhag = len(np.unique(vf[vf[26].astype(float) > 0][6]))\n",
    "    down_rhag = len(np.unique(vf[vf[26].astype(float) < 0][6]))\n",
    "\n",
    "    b = pd.read_csv(\"Cis_piN_Peaks_JanetSong.txt\", sep = \"\\t\", header = None)\n",
    "    up_back = len(np.unique(b[b[23] > 0][3])) - up_rhag\n",
    "    down_back = len(np.unique(b[b[23] < 0][3])) - down_rhag\n",
    "    \n",
    "    if typ == \"RHCTAG\" or typ == \"RCCTAL\":\n",
    "        agree = up_rhag\n",
    "        disagree = down_rhag\n",
    "    else:\n",
    "        agree = down_rhag\n",
    "        disagree = up_rhag\n",
    "    agr += agree\n",
    "    disagr += disagree\n",
    "    print(typ)\n",
    "    print(fisher_exact([[up_rhag, down_rhag], [up_back - up_rhag, down_back - down_rhag]]))\n",
    "    print([[up_rhag, down_rhag], [up_back - up_rhag, down_back - down_rhag]])\n",
    "print(binomtest(agr, agr + disagr, p = 0.5473251028806584))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59de6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fisher_exact([[85, 117 - 85], [266, 486 - 266]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be81cd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot enrichment\n",
    "fig, ax = plt.subplots(figsize = (6, 4))\n",
    "sns.set_style(\"white\")\n",
    "sns.barplot(x = [\"FC exc. neur.\", \"Other cell type\"], y = [0.7941176470588235, 0.5543071161048689], palette = {\"FC exc. neur.\":\"#F42FF5\", \"Other cell type\":\"#40A94D\"})\n",
    "plt.ylabel(\"Proportion agreement in sign\", size = 16)\n",
    "plt.xticks(size = 16)\n",
    "plt.yticks(size = 12)\n",
    "plt.ylim([0.5, 1])\n",
    "plt.title(\"Validation of RAGs and RALs\", size = 20)\n",
    "plt.vlines(0, 0.7931176470588235, 0.9, color='black', linewidth = 3)\n",
    "plt.vlines(1, 0.5523071161048689, 0.9, color='black', linewidth = 3)\n",
    "\n",
    "plt.hlines(0.9, -0.0075, 1.0095, color='black', linewidth = 3)\n",
    "plt.text(0.40, 0.89, \"***\", size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75caba9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"All_Humreffed_HumanDerivedEE_dif_0.025.txt\", sep = \"\\t\", header = None)\n",
    "dfn2 = pd.read_csv(typ + \"_Data_Filt.txt\", sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7aebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reimplementing this to split into chpreffed and humreffed to make it possible to do enrichment analysis relative to background number of sites\n",
    "#That could be RAGs/RALs\n",
    "def get_rha_split(typ, folder, reffed):\n",
    "    if typ.endswith(\"AL\"):\n",
    "        namm = \"NumDown\"\n",
    "    else:\n",
    "        namm = \"NumUp\"\n",
    "    \n",
    "    dff = pd.DataFrame()\n",
    "    files = os.listdir(folder)\n",
    "    files.sort()\n",
    "    for file in files:\n",
    "        if typ in file and \"FetalChondrocytes\" not in file and \"FetalHeartCardiacFibroblasts\" not in file and \"FetalHeartPericytes\" not in file and \"AdultHeartSmoothMuscle\" not in file:\n",
    "            run = False\n",
    "            if (\"Chpreffed\" in file and reffed == \"Chpreffed\") or (\"Chpreffed\" not in file and reffed == \"Humreffed\"):\n",
    "                run = True\n",
    "            if run:\n",
    "                x = pd.read_csv(folder + \"/\" + file, sep = \"\\t\")\n",
    "                x = x[x[namm] >= 3]\n",
    "\n",
    "                x[\"Chrom\"] = [j.split(\":\")[0] for j in x[\"Position\"]]\n",
    "                x[\"Pos\"] = [int(j.split(\":\")[1]) for j in x[\"Position\"]]\n",
    "\n",
    "\n",
    "                prev_row = 0\n",
    "                ind = 0\n",
    "                out = []\n",
    "                for chrom in np.unique(x[\"Chrom\"]):\n",
    "                    x2 = x[x[\"Chrom\"].isin([chrom])]\n",
    "                    x2 = x2.sort_values(\"Pos\")\n",
    "                    for index, row in x2.iterrows():\n",
    "                        if ind == 0:\n",
    "                            prev_row = row\n",
    "                            ind = 1\n",
    "                        elif len(np.intersect1d(prev_row[\"Positions\"].split(\";\"), row[\"Positions\"].split(\";\"))):\n",
    "                            new_poss = \";\".join(np.unique(prev_row[\"Positions\"].split(\";\") + row[\"Positions\"].split(\";\")))\n",
    "                            row[\"Positions\"] = new_poss\n",
    "                            row[namm] = len(new_poss.split(\";\"))\n",
    "                            prev_row = row\n",
    "                        else:\n",
    "                            out.append(prev_row)\n",
    "                            prev_row = row\n",
    "                out.append(prev_row)\n",
    "                df = pd.DataFrame(out)\n",
    "                df[\"Cell type\"] = np.repeat(file.replace(\"_\" + typ + \"s\" + \"_AddSumLFC.txt\", \"\").replace(\"_\" + typ + \"s\" + \"_Chpreffed_AddSumLFC.txt\", \"\"), df.shape[0])\n",
    "                dff = pd.concat([df, dff])\n",
    "    try:\n",
    "        dff = dff.drop([0], axis = 1)\n",
    "    except:\n",
    "        pass\n",
    "    print(dff.shape)\n",
    "    dff = dff.dropna(subset = [\"Position\"])\n",
    "    print(dff.shape)\n",
    "    dff[\"Chrom\"]= [x.split(\":\")[0] for x in dff[\"Position\"]]\n",
    "    dff[\"Pos\"]= [int(x.split(\":\")[1]) for x in dff[\"Position\"]]\n",
    "\n",
    "    out = []\n",
    "    for chrom in np.unique(dff[\"Chrom\"]):\n",
    "        dfc = dff[dff[\"Chrom\"] == chrom].sort_values(\"Pos\")\n",
    "        prev_row = 0\n",
    "        ind = 0\n",
    "        for index, row in dfc.iterrows():\n",
    "            if ind == 0:\n",
    "                prev_row = row\n",
    "                ind = 1\n",
    "            elif len(np.intersect1d(prev_row[\"Positions\"].split(\";\"), row[\"Positions\"].split(\";\"))):\n",
    "                new_poss = \";\".join(np.unique(prev_row[\"Positions\"].split(\";\") + row[\"Positions\"].split(\";\")))\n",
    "                row[\"Positions\"] = new_poss\n",
    "                row[namm] = len(new_poss.split(\";\"))\n",
    "                if prev_row[\"Cell type\"] not in row[\"Cell type\"].split(\";\"):\n",
    "                    row[\"Cell type\"] = row[\"Cell type\"] + \";\" + prev_row[\"Cell type\"]\n",
    "                prev_row = row\n",
    "            else:\n",
    "                out.append(prev_row)\n",
    "                prev_row = row\n",
    "    dfn = pd.DataFrame(out)\n",
    "    num_cts = []\n",
    "    for index, row in dfn.iterrows():\n",
    "        num_cts.append(len(row[\"Cell type\"].split(\";\")))\n",
    "    dfn[\"NumCTS\"] = num_cts\n",
    "    dfn.to_csv(typ + \"_\" + reffed + \"_Data_Filt.txt\", sep = \"\\t\", index = False)\n",
    "    outtt = []\n",
    "    for index, row in dfn.iterrows():\n",
    "        for i in row[\"Positions\"].split(\";\"):\n",
    "            outtt.append(i)\n",
    "    o = pd.DataFrame(outtt)\n",
    "    o.to_csv(typ + \"_\" + reffed + \"_Positions_Filt.txt\", sep = \"\\t\", header = False, index = False)\n",
    "\n",
    "    o[\"Chrom\"] = [j.split(\":\")[0] for j in o[0]]\n",
    "    o[\"Pos1\"] = [str(int(j.split(\":\")[1])-1) for j in o[0]]\n",
    "    o[\"Pos2\"] = [str(int(j.split(\":\")[1])) for j in o[0]]\n",
    "    o[[\"Chrom\", \"Pos1\", \"Pos2\"]].to_csv(typ + \"_\" + reffed + \"_Positions_Filt.bed\", sep = \"\\t\", header = None, index = None)\n",
    "    return dfn\n",
    "#get_rha_split(\"RHCTAG\", \"RHCTAGs\", \"Humreffed\")\n",
    "#get_rha_split(\"RHCTAG\", \"RHCTAGs\", \"Chpreffed\")\n",
    "get_rha_split(\"RHCTAL\", \"RHCTAGs\", \"Humreffed\")\n",
    "get_rha_split(\"RHCTAL\", \"RHCTAGs\", \"Chpreffed\")\n",
    "\n",
    "get_rha_split(\"RCCTAG\", \"RCCTAGs\", \"Humreffed\")\n",
    "get_rha_split(\"RCCTAG\", \"RCCTAGs\", \"Chpreffed\")\n",
    "get_rha_split(\"RCCTAL\", \"RCCTAGs\", \"Humreffed\")\n",
    "get_rha_split(\"RCCTAL\", \"RCCTAGs\", \"Chpreffed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9eca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the human data\n",
    "v, vv = read_noncoding_data_fast(spec_sup = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d23826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the chimp data\n",
    "vv = 0\n",
    "v2 = pd.read_csv(\"Chimp_For_RCAG_Filtered.txt\", sep = \"\\t\")\n",
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52261c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can variously uncomment each one to do that one\n",
    "#For hRALs\n",
    "#dfn = pd.read_csv(\"CTAGL_Split/RHCTAL_Chpreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "#a = pd.read_csv(\"All_Chpreffed_HumanDerived_EE_dif_-0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "#For hRAGs\n",
    "dfn = pd.read_csv(\"CTAGL_Split/RHCTAG_Humreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "a = pd.read_csv(\"All_Humreffed_HumanDerived_EE_dif_0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "#For cRALs\n",
    "#dfn = pd.read_csv(\"CTAGL_Split/RCCTAL_Humreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "#a = pd.read_csv(\"All_Humreffed_ChimpDerived_EE_dif_-0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "#For cRAGs\n",
    "#dfn = pd.read_csv(\"CTAGL_Split/RCCTAG_Chpreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "#a = pd.read_csv(\"All_Chpreffed_ChimpDerived_EE_dif_0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "\n",
    "a = a.set_index(0).join(v.set_index(\"Position\"))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6ce915",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Useful visualization\n",
    "ac = Counter(a[\"NearestGene\"])\n",
    "dc = Counter(dfn[\"NearestGene\"])\n",
    "\n",
    "acr = []\n",
    "dcr = []\n",
    "for i in np.intersect1d(list(ac.keys()), list(dc.keys())):\n",
    "    if ac[i] >= 0:\n",
    "        acr.append(ac[i])\n",
    "        dcr.append(dc[i])\n",
    "\n",
    "sns.regplot(x = dcr, y = acr)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450b3a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = []\n",
    "for key in ac.keys():\n",
    "    if ac[key] >= 250:\n",
    "        keep.append(key)\n",
    "        \n",
    "a2 = a[a[\"NearestGene\"].isin(keep)]\n",
    "dfn2 = dfn[dfn[\"NearestGene\"].isin(keep)]\n",
    "\n",
    "dc2 = Counter(dfn2[\"NearestGene\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67f35b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for key in ac.keys():\n",
    "    if ac[key] >= 250:\n",
    "        if key in dc.keys():\n",
    "            \n",
    "            out.append([key, ac[key], dc[key], fisher_exact([[dc[key], dfn2.shape[0] - dc[key]], [ac[key], a2.shape[0] - ac[key]]])[0], fisher_exact([[dc[key], dfn2.shape[0] - dc[key]], [ac[key], a2.shape[0] - ac[key]]])[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9c5f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(out).sort_values(4)\n",
    "dff[\"FDR\"] = fdrcorrection(dff[4])[1]\n",
    "\n",
    "from scipy.stats import spearmanr,pearsonr\n",
    "print(pearsonr(dff[1], dff[3]))\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3409010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make volcano plot\n",
    "dff[\"-log10(FDR)\"] = -np.log10(dff[\"FDR\"])\n",
    "palette_sig = {\"Not significant\":\"grey\", \"FDR < 0.05\":\"red\"}\n",
    "x = []\n",
    "for index, row in dff.iterrows():\n",
    "    if row[\"FDR\"] < 0.05:\n",
    "        x.append(\"FDR < 0.05\")\n",
    "    else:\n",
    "        x.append(\"Not significant\")\n",
    "dff[\"Significance\"] = x\n",
    "dff.columns = [\"Gene\", \"Num input sites\", \"Num sig\", \"Odds ratio\", \"p-value\", \"FDR\", \"-log10(FDR)\", \"Significance\"]\n",
    "sns.scatterplot(data = dff, x = \"Odds ratio\", y = \"-log10(FDR)\", hue = \"Significance\", palette = palette_sig)\n",
    "plt.title(\"Per gene enrichments for hRAGs\", size = 16)\n",
    "plt.ylabel(\"-Log$_{10}$(FDR)\", size = 14)\n",
    "plt.xlabel(\"Odds ratio\", size = 14)\n",
    "plt.legend(fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea22f6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summing G and L for human (first list) and chimp (second list) using the highest powered comparison\n",
    "#We see that there are still significantly more human CSMD1 regions than chimp CSMD1 regions\n",
    "fisher_exact([[42 + 42, 1987 + 1963 - 84], [27 + 26, 1871 + 1888 - 53]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce38834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This further indicates that the CSMD1 enrichment is human-specific\n",
    "h = pd.read_csv(\"RHCTAG_Data_Filt.txt\", sep = \"\\t\")\n",
    "c = pd.read_csv(\"RCCTAG_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "h_csmd1 = Counter(h[\"NearestGene\"])[\"CSMD1\"]\n",
    "c_csmd1 = Counter(c[\"NearestGene\"])[\"CSMD1\"]\n",
    "\n",
    "print([[h_csmd1, c_csmd1], [h.shape[0] - h_csmd1, c.shape[0] - c_csmd1]])\n",
    "print(fisher_exact([[h_csmd1, c_csmd1], [h.shape[0] - h_csmd1, c.shape[0] - c_csmd1]]))\n",
    "\n",
    "h = pd.read_csv(\"RHCTAL_Data_Filt.txt\", sep = \"\\t\")\n",
    "c = pd.read_csv(\"RCCTAL_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "h_csmd1 = Counter(h[\"NearestGene\"])[\"CSMD1\"]\n",
    "c_csmd1 = Counter(c[\"NearestGene\"])[\"CSMD1\"]\n",
    "\n",
    "print([[h_csmd1, c_csmd1], [h.shape[0] - h_csmd1, c.shape[0] - c_csmd1]])\n",
    "print(fisher_exact([[h_csmd1, c_csmd1], [h.shape[0] - h_csmd1, c.shape[0] - c_csmd1]]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca3c62-b4d1-40dd-948f-70a1f10894e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Volcano plot of GREAT enrichments\n",
    "z = pd.read_csv(\"greatExportAll_GOMF_RHCTAGneur_vs_RCCTAG_neur.tsv\", sep = \"\\t\", skiprows = 3).dropna()\n",
    "out = []\n",
    "for index, row in z.iterrows():\n",
    "    if len(row[\"BgGeneNames\"].split(\",\")) >= 5:\n",
    "        out.append(row)\n",
    "z = pd.DataFrame(out)\n",
    "dff = z.copy()\n",
    "dff[\"-Log$_{10}$(FDR)\"] = -np.log10(dff[\"HyperFdrQ\"])\n",
    "\n",
    "k = []\n",
    "for index, row in dff.iterrows():\n",
    "    if row[\"HyperFdrQ\"] < 0.05:\n",
    "        k.append(\"FDR < 0.05\")\n",
    "    else:\n",
    "        k.append(\"Not significant\")\n",
    "mult = 1.3\n",
    "\n",
    "\n",
    "dff['Significance'] = k\n",
    "fig, ax = plt.subplots(figsize = (9, 6))\n",
    "sns.scatterplot(data = dff, x = \"RegionFoldEnrich\", y = \"-Log$_{10}$(FDR)\", hue = \"Significance\", palette = {\"FDR < 0.05\":\"red\", \"Not significant\":\"grey\"})\n",
    "plt.title(\"hRAG molecular function enrichments\", size = 16*mult)\n",
    "plt.ylabel(\"-Log$_{10}$(FDR)\", size = 14*mult)\n",
    "plt.xlabel(\"Fold-enrichment\", size = 14*mult)\n",
    "plt.xticks(size = 12*mult)\n",
    "plt.yticks(size = 12*mult)\n",
    "plt.legend(fontsize = 12*mult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3eebcf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = dff.loc[0][\"FgGeneNames\"].split(\",\")\n",
    "l23 = pd.read_csv(\"DESeq2_L2-3_IT_Human_Chimp.txt\", sep = \"\\t\")\n",
    "l23 = l23.dropna()\n",
    "l23 = l23[l23[\"padj\"] < 0.25]\n",
    "l23d = l23[l23[\"log2FoldChange\"] < 0]\n",
    "l23u = l23[l23[\"log2FoldChange\"] > 0]\n",
    "down = l23d[l23d[\"Gene\"].isin(genes)].shape[0]\n",
    "up = l23u[l23u[\"Gene\"].isin(genes)].shape[0]\n",
    "\n",
    "from scipy.stats import binomtest\n",
    "binomtest(down, up + down, p = l23d.shape[0]/(l23d.shape[0] + l23u.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d03c877",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Barplot for L2/3 IT neuron genes\n",
    "new_palette = {\"Human\":\"#FF2C0C\", \"Chimp\":\"#0058FF\"}\n",
    "\n",
    "sns.set(font_scale = 1.4)\n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(figsize=(3.5,5))\n",
    "#t_ax = sns.barplot({\"Upregulated\\nin human\":5, \"Downregulated\\nin human\":11}, errorbar=None, linewidth=2.5, edgecolor=\".5\", facecolor='#F2C91140', gap = 0.1, palette = {\"Upregulated\\nin human\":new_palette[\"Human\"], \"Downregulated\\nin human\":new_palette[\"Chimp\"]})\n",
    "t_ax = sns.barplot({\"Upregulated\\nin human\":8, \"Downregulated\\nin human\":1}, errorbar=None, linewidth=2.5, edgecolor=\".5\", facecolor='#F2C91140', gap = 0.1, palette = {\"Upregulated\\nin human\":new_palette[\"Human\"], \"Downregulated\\nin human\":new_palette[\"Chimp\"]})\n",
    "\n",
    "for patch in t_ax.patches:\n",
    "    print(patch.get_x() + patch.get_width()/2)\n",
    "c = 0\n",
    "for patch in t_ax.patches:\n",
    "    if c < 1:\n",
    "        patch.set_edgecolor(new_palette[\"Human\"])\n",
    "        patch.set_facecolor(new_palette[\"Human\"] + \"1A\")\n",
    "    elif c == 1:\n",
    "        patch.set_edgecolor(new_palette[\"Chimp\"])\n",
    "        patch.set_facecolor(new_palette[\"Chimp\"] + \"1A\")\n",
    "    c += 1\n",
    "plt.ylabel(\"Number of genes\")\n",
    "plt.title(\"DLPFC L2/3 IT neurons\")\n",
    "plt.ylim(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall, which cell types are enriched/depleted aren't really distinguishable between human and chimpanzee\n",
    "\n",
    "#For RHCTALs\n",
    "#dfn = pd.read_csv(\"CTAGL_Split/RHCTAL_Chpreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "#a = pd.read_csv(\"All_Chpreffed_HumanDerived_EE_dif_-0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "#For RHCTAGs\n",
    "#dfn = pd.read_csv(\"CTAGL_Split/RHCTAG_Humreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "#a = pd.read_csv(\"All_Humreffed_HumanDerived_EE_dif_0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "#For RCCTALs\n",
    "dfn = pd.read_csv(\"CTAGL_Split/RCCTAL_Humreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "a = pd.read_csv(\"All_Humreffed_ChimpDerived_EE_dif_-0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "#For RCCTAGs\n",
    "#dfn = pd.read_csv(\"CTAGL_Split/RCCTAG_Chpreffed_Data_Filt.txt\", sep = \"\\t\")\n",
    "#a = pd.read_csv(\"All_Chpreffed_ChimpDerived_EE_dif_0.025.txt\", sep = \"\\t\", header = None)\n",
    "\n",
    "back_num = Counter(a[1])\n",
    "\n",
    "fl = []\n",
    "flu = []\n",
    "for index, row in dfn.iterrows():\n",
    "    for i in row[\"Cell type\"].split(\";\"):\n",
    "        fl.append(i)\n",
    "        if len(row[\"Cell type\"].split(\";\")) == 1:\n",
    "            flu.append(row[\"Cell type\"])\n",
    "for_num = Counter(fl)\n",
    "back_num = back_num - for_num\n",
    "for_numu = Counter(flu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e072bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chisquare\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "z = []\n",
    "out = []\n",
    "exclude = [\"FetalHeartCardiacFibroblasts\", \"AdultHeartSmoothMuscle\", \"FetalHeartEndocardium\", \"FetalHeartPericytes\", \"KosoyRoussosControlMicroglia\"]\n",
    "for key in for_num:\n",
    "    if key not in exclude:\n",
    "        x.append(for_num[key])\n",
    "        y.append(back_num[key])\n",
    "        z.append(for_numu[key])\n",
    "    out.append([key, for_num[key], back_num[key], for_numu[key], for_num[key]/back_num[key]])\n",
    "    \n",
    "print(chisquare([x, y]))\n",
    "df = pd.DataFrame(out)\n",
    "df.sort_values(3)\n",
    "df2 = df.copy()\n",
    "df2 = df[~df[0].isin(exclude)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea04b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = np.polyfit(y, x, 1)\n",
    "\n",
    "bp = []\n",
    "bstat = []\n",
    "for index, row in df2.iterrows():\n",
    "    bres = binomtest(row[1], row[1] + round(a*row[2] + b))\n",
    "    bp.append(bres.pvalue)\n",
    "    bstat.append(bres.statistic)\n",
    "df2[\"Binomial p-value\"] = bp\n",
    "df2[\"Binomial statistic\"] = bstat\n",
    "df2 = df2.sort_values(\"Binomial p-value\")\n",
    "df2[\"FDR\"] = fdrcorrection(df2[\"Binomial p-value\"])[1]\n",
    "df2.sort_values(\"Binomial statistic\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1aa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking on GC-biased gene conversion\n",
    "x = pd.read_csv(\"ASE_SNPs.FILTER.SPLIT_SPECIES.bed\", sep = \"\\t\", header = None)\n",
    "x[\"Position\"] = x[0] + \":\" + x[2].astype(str)\n",
    "x = x[[3, \"Position\"]]\n",
    "x.columns = [\"Mut\", \"Position\"]\n",
    "x = x.set_index(\"Position\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Background for all sites\n",
    "x[\"Position\"] = x.index\n",
    "x_ws = x[x[\"Mut\"].isin([\"C|A\", \"G|A\", \"C|T\", \"G|T\"])]\n",
    "x_sw = x[x[\"Mut\"].isin([\"A|C\", \"A|G\", \"T|C\", \"T|G\"])]\n",
    "\n",
    "x_ww_ss = x[~x[\"Position\"].isin(list(x_ws[\"Position\"]) + list(x_sw[\"Position\"]))]\n",
    "\n",
    "tot = x_ws.shape[0] + x_sw.shape[0] + x_ww_ss.shape[0]\n",
    "print(x_ws.shape[0]/tot, x_sw.shape[0]/tot, x_ww_ss.shape[0]/tot)\n",
    "x = x.drop([\"Position\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5ae2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"RHCTAG_Positions_Filt.txt\", sep = \"\\t\", header = None)\n",
    "v.index = v[0]\n",
    "\n",
    "v = v.join(x)\n",
    "\n",
    "v[\"Position\"] = v.index\n",
    "v_ws = v[v[\"Mut\"].isin([\"C|A\", \"G|A\", \"C|T\", \"G|T\"])]\n",
    "v_sw = v[v[\"Mut\"].isin([\"A|C\", \"A|G\", \"T|C\", \"T|G\"])]\n",
    "v_ww_ss = v[~v[\"Position\"].isin(list(v_ws[\"Position\"]) + list(v_sw[\"Position\"]))]\n",
    "\n",
    "tot = v_ws.shape[0] + v_sw.shape[0] + v_ww_ss.shape[0]\n",
    "print(v_ws.shape[0]/tot, v_sw.shape[0]/tot, v_ww_ss.shape[0]/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5878387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing to HAQERs\n",
    "v = pd.read_csv(\"hCONDELs_HAQERs_HARs/HumChp_NC_Final_Rmdup_CREs_NoHLA_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "v.index = v[0] + \":\" + v[2].astype(str)\n",
    "\n",
    "v = v.join(x)\n",
    "\n",
    "v[\"Position\"] = v[0] + \":\" + v[2].astype(str)\n",
    "v_ws = v[v[\"Mut\"].isin([\"C|A\", \"G|A\", \"C|T\", \"G|T\"])]\n",
    "v_sw = v[v[\"Mut\"].isin([\"A|C\", \"A|G\", \"T|C\", \"T|G\"])]\n",
    "v_ww_ss = v[~v[\"Position\"].isin(list(v_ws[\"Position\"]) + list(v_sw[\"Position\"]))]\n",
    "\n",
    "tot = v_ws.shape[0] + v_sw.shape[0] + v_ww_ss.shape[0]\n",
    "print(v_ws.shape[0]/tot, v_sw.shape[0]/tot, v_ww_ss.shape[0]/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb685f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparing to HARs\n",
    "v = pd.read_csv(\"hCONDELs_HAQERs_HARs/HumChp_NC_Final_Rmdup_CREs_NoHLA_HARs.bed\", sep = \"\\t\", header = None)\n",
    "v.index = v[0] + \":\" + v[2].astype(str)\n",
    "\n",
    "v = v.join(x)\n",
    "\n",
    "v[\"Position\"] = v[0] + \":\" + v[2].astype(str)\n",
    "v_ws = v[v[\"Mut\"].isin([\"C|A\", \"G|A\", \"C|T\", \"G|T\"])]\n",
    "v_sw = v[v[\"Mut\"].isin([\"A|C\", \"A|G\", \"T|C\", \"T|G\"])]\n",
    "v_ww_ss = v[~v[\"Position\"].isin(list(v_ws[\"Position\"]) + list(v_sw[\"Position\"]))]\n",
    "\n",
    "tot = v_ws.shape[0] + v_sw.shape[0] + v_ww_ss.shape[0]\n",
    "print(v_ws.shape[0]/tot, v_sw.shape[0]/tot, v_ww_ss.shape[0]/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c04b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#HARsv2_0485,HARsv2_2285,HARsv2_0943 is highly conserved example\n",
    "#Enrichment for HARs in loss of function in neurons\n",
    "v = pd.read_csv(\"Reinforcing_Intersect/RHCTAL_Positions_Filt_HARs.bed\", sep = \"\\t\", header = None)\n",
    "v = v[v[4] != -1]\n",
    "v[\"Position\"] = v[0] + \":\" + v[2].astype(str)\n",
    "v = v[[\"Position\", 6, 7, 8, 9]]\n",
    "vv = pd.read_csv(\"RHCTAL_Data.txt\", sep = \"\\t\")\n",
    "v = vv.set_index(\"Position\").join(v.set_index(\"Position\")).dropna().sort_values(\"Cell type\")\n",
    "\n",
    "neur_har = v[v[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])].shape[0]\n",
    "all_har = v.shape[0]\n",
    "all_nhar = vv.shape[0] - all_har\n",
    "neur_nhar = vv[vv[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])].shape[0] - neur_har\n",
    "#Enriched for cell type-specific losses in neuronal cells unsurprisingly\n",
    "print([[neur_har, all_har - neur_har], [neur_nhar, all_nhar]])\n",
    "fisher_exact([[neur_har, all_har - neur_har], [neur_nhar, all_nhar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee6107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In contrast, we do not see enrichment for gain of accessibility in neuronal HARs\n",
    "#If we switch the name to HAQER, we also don't see any kind of enrichment\n",
    "#Suggests that at least a subset of HARs result in reinforcing neuron-specific loss of accessibility!\n",
    "v = pd.read_csv(\"Reinforcing_Intersect/RHCTAG_Positions_Filt_HARs.bed\", sep = \"\\t\", header = None)\n",
    "v = v[v[4] != -1]\n",
    "v[\"Position\"] = v[0] + \":\" + v[2].astype(str)\n",
    "v = v[[\"Position\", 6, 7, 8, 9]]\n",
    "vv = pd.read_csv(\"RHCTAG_Data.txt\", sep = \"\\t\")\n",
    "v = vv.set_index(\"Position\").join(v.set_index(\"Position\")).dropna().sort_values(\"Cell type\")\n",
    "\n",
    "neur_har = v[v[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])].shape[0]\n",
    "all_har = v.shape[0]\n",
    "all_nhar = vv.shape[0] - all_har\n",
    "neur_nhar = vv[vv[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])].shape[0] - neur_har\n",
    "#Enriched for cell type-specific losses in neuronal cells unsurprisingly\n",
    "fisher_exact([[neur_har, all_har - neur_har], [neur_nhar, all_nhar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ddb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir():\n",
    "    if file.startswith(\"All\") and \"EE_dif\" in file and \".bed\" not in file and \"Derived\" in file:\n",
    "        o = pd.read_csv(file, sep = \"\\t\", header = None)\n",
    "        o[\"Chrom\"] = [j.split(\":\")[0] for j in o[0]]\n",
    "        o[\"Pos1\"] = [str(int(j.split(\":\")[1])-1) for j in o[0]]\n",
    "        o[\"Pos2\"] = [str(int(j.split(\":\")[1])) for j in o[0]]\n",
    "        o[[\"Chrom\", \"Pos1\", \"Pos2\", 1]].to_csv(file.replace(\".txt\", \".bed\"), sep = '\\t', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a554419",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Significant enrichment for HAQERs\n",
    "v = pd.read_csv(\"CTAGL_Split/RHCTAG_Humreffed_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "b = pd.read_csv(\"CTAGL_Split/All_Humreffed_HumanDerived_EE_dif_0.025_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "#v = pd.read_csv(\"CTAGL_Split/RHCTAL_Chpreffed_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "#b = pd.read_csv(\"CTAGL_Split/All_Chpreffed_HumanDerived_EE_dif_-0.025_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "v2 = v[v[4] != -1]\n",
    "b2 = b[b[5] != -1]\n",
    "inter = len(np.unique(v2[9]))\n",
    "back = len(np.unique(b2[9]))\n",
    "\n",
    "print([[inter, back], [v.shape[0], b.shape[0]]])\n",
    "print(fisher_exact([[inter, back], [v.shape[0], b.shape[0]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e81457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Significant enrichment for HAQERs\n",
    "#v = pd.read_csv(\"CTAGL_Split/RHCTAG_Humreffed_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "#b = pd.read_csv(\"CTAGL_Split/All_Humreffed_HumanDerived_EE_dif_0.025_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "v = pd.read_csv(\"CTAGL_Split/RHCTAL_Chpreffed_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "b = pd.read_csv(\"CTAGL_Split/All_Chpreffed_HumanDerived_EE_dif_-0.025_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "v2 = v[v[4] != -1]\n",
    "b2 = b[b[5] != -1]\n",
    "inter = len(v2[9])\n",
    "back = len(b2[9])\n",
    "\n",
    "print([[inter, back], [v.shape[0], b.shape[0]]])\n",
    "print(fisher_exact([[inter, back], [v.shape[0], b.shape[0]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3081fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"Fixed_LiangSteinNeuron.txt.gz\", sep = \"\\t\")\n",
    "vv = pd.read_csv(\"Poly_MAF0.25_LiangSteinNeuron.txt.gz\", sep = \"\\t\")\n",
    "\n",
    "\n",
    "try:\n",
    "    vv = add_unfold(vv)\n",
    "    vv_ref = vv[vv[\"Human ref\"] == vv[\"Chimp ref\"]]\n",
    "    vv_alt = vv[vv[\"Human alt\"] == vv[\"Chimp ref\"]]\n",
    "    vv_ref[\"fixed logfc\"] = -vv_ref[\"logfc\"].astype(float)\n",
    "    vv_alt[\"fixed logfc\"] = vv_alt[\"logfc\"].astype(float)\n",
    "    vv = pd.concat([vv_ref, vv_alt])\n",
    "except:\n",
    "    pass\n",
    "\n",
    "te_blacklist = pd.read_csv(\"BlacklistTE_Variants.txt\", sep = \"\\t\")\n",
    "    \n",
    "v = v[~v[\"Position\"].isin(te_blacklist[\"Position\"])]\n",
    "vv = vv[~vv[\"Position\"].isin(te_blacklist[\"Position\"])]\n",
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting neuronal hRAG/hRAL\n",
    "dfn = pd.read_csv(\"RHCTAL_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "\n",
    "keep = []\n",
    "for index, row in dfn.iterrows():\n",
    "    if row[\"Cell type\"] in [\"LiangSteinNeuron\", \"ITL23\", \"LiangSteinNeuron;ITL23\", \"ITL23;LiangSteinNeuron\"]:\n",
    "        keep = keep + [row[\"Position\"].split(\":\")[0] + \":\" + str(i) for i in range(int(row[\"Position\"].split(\":\")[1]) - 500, int(row[\"Position\"].split(\":\")[1]) + 500)]\n",
    "\n",
    "dfn = pd.read_csv(\"RHCTAG_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "for index, row in dfn.iterrows():\n",
    "    if row[\"Cell type\"] in [\"LiangSteinNeuron\", \"ITL23\", \"LiangSteinNeuron;ITL23\", \"ITL23;LiangSteinNeuron\"]:\n",
    "        keep = keep + [row[\"Position\"].split(\":\")[0] + \":\" + str(i) for i in range(int(row[\"Position\"].split(\":\")[1]) - 500, int(row[\"Position\"].split(\":\")[1]) + 500)]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3eb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vx = v[v[\"Position\"].isin(keep)]\n",
    "vvx = vv[vv[\"Position\"].isin(keep)]\n",
    "\n",
    "vx = vx[vx[\"SpecSup447\"] > 250]\n",
    "vvx = vvx[vvx[\"SpecSup447\"] > 250]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d740a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfari = pd.read_csv(\"SFARI-Gene_genes_03-28-2024release_05-09-2024export.csv\")\n",
    "sfari = sfari[sfari[\"gene-score\"] == 1]\n",
    "sfari = {\"SFARI\":list(sfari[\"gene-symbol\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "syngo = pd.read_csv(\"../Cell_Type_Prop/Cell_Type_Prop/syngo_genes.csv\")\n",
    "syngo = syngo[\"hgnc_symbol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3b950",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing for positive selection using conservation scores\n",
    "vx = vx[vx[\"SpecSup447\"] > 250]\n",
    "vvx = vvx[vvx[\"SpecSup447\"] > 250]\n",
    "\n",
    "cuttt = 0.9\n",
    "\n",
    "z = list(vvx[\"PhyloP447\"])\n",
    "z.sort()\n",
    "cutoff = z[int(floor((len(z)*cuttt)))]\n",
    "\n",
    "vvv = prepare_alpha(vx, vvx)\n",
    "alpha = compute_alpha_cutoff(vvv, plot = True, cutoff = cutoff, window = [-5, 12], title = \"PhyloP distribution for neuronal hRAGs and hRALs\")\n",
    "print(alpha)\n",
    "print((fisher_exact(alpha[-2], alternative = \"greater\")[1] + fisher_exact(alpha[-3], alternative = \"greater\")[1])/2)\n",
    "\n",
    "#plt.title(\"\")\n",
    "#plt.xlabel(\"\")\n",
    "#plt.ylabel(\"\")\n",
    "#plt.xticks([], [])\n",
    "#plt.yticks([], [])\n",
    "#plt.legend([], [], frameon = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc3173",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfn = pd.read_csv(\"RHCTAL_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "out = []\n",
    "for index, row in dfn.iterrows():\n",
    "    if row[\"Cell type\"] in [\"LiangSteinNeuron\", \"ITL23\", \"LiangSteinNeuron;ITL23\", \"ITL23;LiangSteinNeuron\"]:\n",
    "        pos = [row[\"Position\"].split(\":\")[0] + \":\" + str(i) for i in range(int(row[\"Position\"].split(\":\")[1]) - 500, int(row[\"Position\"].split(\":\")[1]) + 500)]\n",
    "        f = np.maximum(list(vx[vx[\"Position\"].isin(pos)][\"PhyloP447\"]), 0)\n",
    "        p = np.maximum(list(vvx[vvx[\"Position\"].isin(pos)][\"PhyloP447\"]), 0)\n",
    "        out.append([row[\"Position\"], np.sum(f), np.sum(p), np.sum(f) - np.sum(p)])\n",
    "dfnn = pd.DataFrame(out)\n",
    "dfnn.columns = [\"Position\", \"Fixed PhyloP Sum\", \"Poly PhyloP Sum\", \"Difference in PhyloP\"]\n",
    "dfnn.to_csv(\"RHCTAL_Data_Filt_wPhyloPSum.txt\", sep = \"\\t\", index = False)\n",
    "dfnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66a42c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfn = pd.read_csv(\"RHCTAG_Data_Filt.txt\", sep = \"\\t\")\n",
    "\n",
    "out = []\n",
    "for index, row in dfn.iterrows():\n",
    "    if row[\"Cell type\"] in [\"LiangSteinNeuron\", \"ITL23\", \"LiangSteinNeuron;ITL23\", \"ITL23;LiangSteinNeuron\"]:\n",
    "        pos = [row[\"Position\"].split(\":\")[0] + \":\" + str(i) for i in range(int(row[\"Position\"].split(\":\")[1]) - 500, int(row[\"Position\"].split(\":\")[1]) + 500)]\n",
    "        f = np.maximum(list(vx[vx[\"Position\"].isin(pos)][\"PhyloP447\"]), 0)\n",
    "        p = np.maximum(list(vvx[vvx[\"Position\"].isin(pos)][\"PhyloP447\"]), 0)\n",
    "        out.append([row[\"Position\"], np.sum(f), np.sum(p), np.sum(f) - np.sum(p)])\n",
    "dfnn = pd.DataFrame(out)\n",
    "dfnn.columns = [\"Position\", \"Fixed PhyloP Sum\", \"Poly PhyloP Sum\", \"Difference in PhyloP\"]\n",
    "dfnn.to_csv(\"RHCTAG_Data_Filt_wPhyloPSum.txt\", sep = \"\\t\", index = False)\n",
    "dfnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d363b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "#High PhyloP ones are enriched for developing cortical neurons for RHCTALs and RHCTAGs\n",
    "print(fisher_exact([[28, 12], [445, 838]]))\n",
    "\n",
    "print(fisher_exact([[29, 16], [488, 899]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7cffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Significant enrichment for HAQERs\n",
    "v = pd.read_csv(\"CTAGL_Split/RHCTAG_Humreffed_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "b = pd.read_csv(\"CTAGL_Split/All_Humreffed_HumanDerived_EE_dif_0.025_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "#v = pd.read_csv(\"CTAGL_Split/RHCTAL_Chpreffed_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "#b = pd.read_csv(\"CTAGL_Split/All_Chpreffed_HumanDerived_EE_dif_-0.025_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "v2 = v[v[4] != -1]\n",
    "b2 = b[b[5] != -1]\n",
    "inter = len(v2[9])\n",
    "back = len(b2[9])\n",
    "\n",
    "print([[inter, back], [v.shape[0], b.shape[0]]])\n",
    "print(fisher_exact([[inter, back], [v.shape[0], b.shape[0]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303da308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Significant enrichment for HARs\n",
    "#v = pd.read_csv(\"CTAGL_Split/RHCTAG_Humreffed_Positions_Filt_HARs.bed\", sep = \"\\t\", header = None)\n",
    "#b = pd.read_csv(\"CTAGL_Split/All_Humreffed_HumanDerived_EE_dif_0.025_HARs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "v = pd.read_csv(\"CTAGL_Split/RHCTAL_Chpreffed_Positions_Filt_HARs.bed\", sep = \"\\t\", header = None)\n",
    "b = pd.read_csv(\"CTAGL_Split/All_Chpreffed_HumanDerived_EE_dif_-0.025_HARs.bed\", sep = \"\\t\", header = None)\n",
    "\n",
    "v2 = v[v[4] != -1]\n",
    "b2 = b[b[5] != -1]\n",
    "inter = len(np.unique(v2[9]))\n",
    "back = len(np.unique(b2[9]))\n",
    "\n",
    "print([[inter, back], [v.shape[0], b.shape[0]]])\n",
    "print(fisher_exact([[inter, back], [v.shape[0], b.shape[0]]]))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c56ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting number of intersections with HARs/HAQERs\n",
    "v = pd.read_csv(\"Reinforcing_Intersect/RHCTAG_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "len(np.unique(v[v[4] != -1][9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969f621b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"Reinforcing_Intersect/RHCTAL_Positions_Filt_HAQERs.bed\", sep = \"\\t\", header = None)\n",
    "len(np.unique(v[v[4] != -1][9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d5859f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"Reinforcing_Intersect/RHCTAG_Positions_Filt_HARs.bed\", sep = \"\\t\", header = None)\n",
    "len(np.unique(v[v[4] != -1][9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0cb650",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = pd.read_csv(\"Reinforcing_Intersect/RHCTAL_Positions_Filt_HARs.bed\", sep = \"\\t\", header = None)\n",
    "len(np.unique(v[v[4] != -1][9]))\n",
    "p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68fe112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting\n",
    "sns.barplot({\"HAQER hRALs\":19, \"HAQER hRAGs\":18, \"HAR hRALs\":46, \"HAR hRAGs\":50}, palette = {\"HAR hRALs\":\"#F5009E\", \"HAR hRAGs\":\"#F5009E\", \"HAQER hRALs\":\"#3400F5\", \"HAQER hRAGs\":\"#3400F5\"})\n",
    "plt.ylabel(\"Count\", size = 16)\n",
    "plt.xlabel(\"Category\", size = 16)\n",
    "plt.xticks(size = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91ecbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting odds ratios for enrichment for HARs/HAQERs\n",
    "#Not used\n",
    "\n",
    "haqer_gain = [3.185953, 1.85716]\n",
    "haqer_loss = [3.541672955595134, 2.063902]\n",
    "har_gain = [2.1054515856718776, 1.567764]\n",
    "har_loss = [2.1681048195978367, 1.607965]\n",
    "\n",
    "# Example data\n",
    "categories = ['HAQER gain', 'HAQER loss', 'HAR Gain', 'HAR loss']\n",
    "values = [haqer_gain[0], haqer_loss[0], har_gain[0], har_loss[0]]\n",
    "lower_ci = [haqer_gain[0] - haqer_gain[1], haqer_loss[0] - haqer_loss[1], har_gain[0] - har_gain[1], har_loss[0] - har_loss[1]]  # Lower confidence intervals\n",
    "\n",
    "# Create the bar plot\n",
    "plt.bar(categories, values, color=[\"#F42FF5\", \"#F42FF5\", \"#F42FF5\", \"#F42FF5\"], label='Values', alpha = 0.8)\n",
    "\n",
    "# Add lower confidence intervals as error bars\n",
    "for i, (x, y, ci) in enumerate(zip(categories, values, lower_ci)):\n",
    "    plt.vlines(x, y - ci, y, color='black', label='Lower CI' if i == 0 else \"\")\n",
    "    plt.hlines(y - ci, i-0.125, i+0.125, color='black')\n",
    "    #if i == 0:\n",
    "    #    plt.text(i - 0.025, y-0.025, \"*\", size = 20)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Gene set', size = 16)\n",
    "plt.ylabel('Odds ratio', size = 16)\n",
    "plt.title('HAR/HAQER enrichment', size = 16)\n",
    "plt.legend([], [], frameon = False)\n",
    "plt.xticks(size = 14)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1e5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#In contrast, we do not see enrichment for gain of accessibility in neuronal HARs\n",
    "#If we switch the name to HAQER, we also don't see any kind of enrichment\n",
    "#Suggests that at least a subset of HARs result in reinforcing neuron-specific loss of accessibility!\n",
    "v = pd.read_csv(\"Reinforcing_Intersect/RHCTAG_Positions_Filt_HARs.bed\", sep = \"\\t\", header = None)\n",
    "v = v[v[4] != -1]\n",
    "v[\"Position\"] = v[0] + \":\" + v[2].astype(str)\n",
    "v = v[[\"Position\", 6, 7, 8, 9]]\n",
    "vv = pd.read_csv(\"RHCTAG_Data.txt\", sep = \"\\t\")\n",
    "v = vv.set_index(\"Position\").join(v.set_index(\"Position\")).dropna().sort_values(\"Cell type\")\n",
    "\n",
    "neur_har = v[v[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])].shape[0]\n",
    "all_har = v.shape[0]\n",
    "all_nhar = vv.shape[0] - all_har\n",
    "neur_nhar = vv[vv[\"Cell type\"].isin([\"LiangSteinNeuron\", \"ITL23\", \"ITL23;LiangSteinNeuron\", \"LiangSteinNeuron;ITL23\"])].shape[0] - neur_har\n",
    "#Enriched for cell type-specific losses in neuronal cells unsurprisingly\n",
    "print([[neur_har, all_har - neur_har], [neur_nhar, all_nhar - neur_nhar]])\n",
    "fisher_exact([[neur_har, all_har - neur_har], [neur_nhar, all_nhar - neur_nhar]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68de97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for neuronal enrichment plotting\n",
    "\n",
    "haqer_gain = [0.8803048416019127, 0.1619834, 3.1600577]\n",
    "haqer_loss = [0.2656925, 0.006281717, 1.749395345]\n",
    "har_gain = [1.0607914399873586, 0.4203745, 2.3655518]\n",
    "har_loss = [2.815629742033384, 1.336993, 5.801577]\n",
    "\n",
    "plt.subplots(figsize = (6*1.3, 4*1.3))\n",
    "\n",
    "# Example data\n",
    "categories = ['HAQER hRAG', 'HAQER hRAL', 'HAR hRAG', 'HAR hRAL']\n",
    "values = [haqer_gain[0], haqer_loss[0], har_gain[0], har_loss[0]]\n",
    "lower_ci = [haqer_gain[0] - haqer_gain[1], haqer_loss[0] - haqer_loss[1], har_gain[0] - har_gain[1], har_loss[0] - har_loss[1]]  # Lower confidence intervals\n",
    "upper_ci = [haqer_gain[2] - haqer_gain[0], haqer_loss[2] - haqer_loss[0], har_gain[2] - har_gain[0], har_loss[2] - har_loss[0]]\n",
    "# Create the bar plot\n",
    "plt.bar(categories, values, color=[\"#40A94D\", \"#40A94D\", \"#40A94D\", \"#F42FF5\"], label='Values', alpha = 0.8)\n",
    "\n",
    "# Add lower confidence intervals as error bars\n",
    "for i, (x, y, ci) in enumerate(zip(categories, values, lower_ci)):\n",
    "    plt.vlines(x, y - ci, y, color='black', label='Lower CI' if i == 0 else \"\")\n",
    "    plt.hlines(y - ci, i-0.125, i+0.125, color='black')\n",
    "    plt.vlines(x, y, y + ci, color='black', label='Lower CI' if i == 0 else \"\")\n",
    "    plt.hlines(y + ci, i-0.125, i+0.125, color='black')\n",
    "    #if i == 0:\n",
    "    #    plt.text(i - 0.025, y-0.025, \"*\", size = 20)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('Gene set', size = 16)\n",
    "plt.ylabel('Odds ratio', size = 16)\n",
    "plt.title('Enrichment for neuronal CREs', size = 18)\n",
    "plt.legend([], [], frameon = False)\n",
    "plt.xticks(size = 12)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
